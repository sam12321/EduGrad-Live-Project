{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edu-Grad Live Project\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task - 1: Importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing dataset\n",
    "dat = pd.read_csv(r'C:\\Users\\bhavy\\OneDrive\\Documents\\Edugrad Live Project\\OnlineNewsPopularity.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task - 2: Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "head() got an unexpected keyword argument 'max_col'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-658ca6516cb1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# displaying first five rows\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: head() got an unexpected keyword argument 'max_col'"
     ]
    }
   ],
   "source": [
    "# displaying first five rows\n",
    "pd.set_option('display.max_column')\n",
    "dat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting dimensions of dataset\n",
    "dat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysing dataset using describe function\n",
    "dat.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# finding mean of all columns\n",
    "dat.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# finding median of all columns\n",
    "dat.median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task - 3: Finding Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the count of null values in each column\n",
    "dat.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task - 4: Handling Null Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So,now we know which of these columns contain null values. These columns are as follows :\n",
    "- n_unique_tokens - 1\n",
    "- sentence_importance - 16\n",
    "- average_token_length - 3\n",
    "- data_channel_is_lifestyle - 1\n",
    "- data_channel_is_entertainment - 1\n",
    "- data_channel_is_bus - 1\n",
    "- data_channel_is_tech - 1             \n",
    "- kw_min_max - 1\n",
    "- kw_max_max - 25\n",
    "- kw_avg_max - 1\n",
    "- kw_avg_avg - 1\n",
    "- global_rate_positive_words - 1\n",
    "- shares - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat['url'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in dat.columns:\n",
    "    if(dat[i].isnull().sum()!=0):\n",
    "        dat[i].fillna(dat[i].mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dat.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task - 5: Visualization Of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train_data.revenue.hist()\n",
    "plt.style.use('seaborn')\n",
    "sns.set_style('whitegrid')\n",
    "ax,fig=plt.subplots(figsize=(16,6))\n",
    "plt.subplot(1,2,1)\n",
    "#plt.hist(train_data.revenue)\n",
    "sns.distplot(dat[' shares'],kde=False)\n",
    "plt.title('Revenue')\n",
    "plt.subplot(1,2,2)\n",
    "#plt.hist(np.log(train_data['revenue']))\n",
    "sns.distplot(np.log(dat[' shares']),kde=False)\n",
    "plt.title(\"Log(Revenue) Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.catplot(x=' is_weekend',y=' shares',data=dat)\n",
    "plt.title('relation betweeen day of release and shares')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above graph we can clearly see that articles published on weekdays were shared more compared to articles shared on weekends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getshares(col):\n",
    "    result=dat[dat[col]==1][' shares']\n",
    "    return result\n",
    "\n",
    "mon=getshares(' weekday_is_monday')\n",
    "tue=getshares(' weekday_is_tuesday')\n",
    "wed=getshares(' weekday_is_wednesday')\n",
    "thu=getshares(' weekday_is_thursday')\n",
    "fri=getshares(' weekday_is_friday')\n",
    "sat=getshares(' weekday_is_saturday')\n",
    "sun=getshares(' weekday_is_sunday')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame([mon,tue,wed,thu,fri,sat,sun])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mon=dat[dat[' weekday_is_monday']==1][' shares']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mon.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plotting a graph to compare no. of words with no. of shares\n",
    "sns.scatterplot(x=' n_tokens_content',y=' shares',data=dat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above graph we can see that smaller articles(i.e articles with  less no. of words) were more shared compares to longer articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
